import type { ChatCompletionMessageParam } from "openai/resources/chat/completions";
import { aiFunctionExecuter } from "./function-calls";
import { isContentAllowed } from "./content-filter";
import { classifyMessage } from "./message-classifier";
import { classifyFunctionMessage } from "./function-classifier";
import log from "../../log";
import type { GenericFormEntry, ServerChatItem } from "./shared-types";
import { chatStore } from "./chat-history";
import { generateKnowledgebaseAnswer } from "../generation";

/*
Diese Biliothek dient nicht dem allgemeinen Chat!
Sie wir explizit genutzt, wenn nur MIT der App direkt interagiert wird.
D.h. es wird IMMER automatisch davon ausgegangen dass ein Funktions-Aufruf
oder eine Wissensabfrage gemacht wird.
Es kann keine sonstigen Nachrichten verarbeitet!!!
*/

/**
 * MAIN FUNCTION
 * Handles the chat with the user.
 * The server can cache the chat history by providing a chatId.
 * The chatId can be generated by the client or by the server.
 * - will check if the message is allowed
 * - will classify the message (function or knowledge)
 * - function? => execute the function
 * - knowledge? => answer the knowledge question
 * - continue? => continue the chat
 */
export const functionChat = async (
  chatId: string | undefined,
  messages: ChatCompletionMessageParam[]
): Promise<ServerChatItem> => {
  // get the session or create a new one
  const session = chatStore.get(chatId);

  try {
    // Append messages if history exists, otherwise set initial messages
    if (session.messages.length > 0) {
      session.messages.push(messages[messages.length - 1]);
    } else {
      session.messages = [...messages];
    }

    // Log the session
    await log.debug(
      session.id,
      `ChatHistory>Len:${session.messages.length},state:${JSON.stringify(session.state)}`
    );
    await log.logAChat(session.id, ...session.messages);

    // Use Content Filter
    const isAllowed = true; //await isContentAllowed(lastUserMessage);
    if (!isAllowed) {
      return {
        chatId: session.id,
        role: "assistant",
        content:
          "I´m sorry, but I can´t answer that question. (Content Filter)",
        renderType: "text",
      };
    }

    // Classify message
    // ...if the state is empty yet
    if (Object.keys(session.state).length === 0) {
      const messageType = await classifyMessage(session.messages);
      if (messageType === "knowledge") {
        session.state.knowledgeMode = true;
      } else if (messageType === "function") {
        session.state.functionMode = true;
      } else if (messageType === "follow-up") {
        session.state.followUp = true;
      }
      await log.debug(session.id, "detected message-type", messageType);
    }

    // Handle follow-up mode
    if (session.state.followUp) {
      return {
        chatId: session.id,
        role: "assistant",
        content: "Please continue your question.",
        renderType: "box",
        type: "error",
      };
    }

    // Handle knowledge mode
    if (session.state.knowledgeMode) {
      const response = await generateKnowledgebaseAnswer(
        messages[messages.length - 1].content as string,
        {
          countChunks: 5,
          addBeforeN: 1,
          addAfterN: 1,
        }
      );

      // Reset session
      session.messages = [];
      session.state = {};

      return {
        chatId: session.id,
        role: "assistant",
        content: response.message.content,
        renderType: "box",
        type: "info",
      };
    }

    // else handle function mode
    // check if the message call has all necessary fields and if a function was detected
    const funcClassification = await classifyFunctionMessage(session.messages);

    // Was a function call detected with a known function call?
    // If not, we will reset the chat history and ask the user to try again with another prompt.
    if (funcClassification.data.functionName === "unknown") {
      return {
        chatId: session.id,
        role: "assistant",
        content:
          "I am sorry. I don´t have a function that could solve your request. Please try again with another prompt.",
        renderType: "box",
        type: "error",
      };
    }

    // All other functions should be executable. We will try to handle them here.
    session.state.functionMode = true;

    if (funcClassification.data.missingFields.length === 0) {
      const functionCall = {
        name: funcClassification.data.functionName,
        arguments: funcClassification.data.knownFields,
      };
      const functionResponse = await aiFunctionExecuter(
        functionCall.name,
        funcClassification.data.knownFields
      ).catch(async (e) => {
        await log.debug(session.id, "Error executing function", e);
        throw e;
      });
      await log.debug(
        session.id,
        "functionResponse",
        JSON.stringify(functionResponse)
      );

      // back to the user. Reset the chat history to start a new one since it can make problems
      // if different questions and actions are handled in the same chat.
      return {
        chatId: session.id,
        role: "assistant",
        content: functionResponse.message,
        renderType: "text",
      };
    }

    // If we reach this point, we have a function call with missing fields.
    // We will return a message asking the user to provide the missing fields.
    else {
      // Create form definition from missing fields
      const formDefinition: GenericFormEntry[] =
        funcClassification.data.missingFields.map((field) => ({
          type: "text",
          label: field,
          key: field,
        }));

      // Create an object with missing fields as keys and empty strings as values
      const missingFieldsData = Object.fromEntries(
        funcClassification.data.missingFields.map((field) => [field, ""])
      );

      return {
        chatId: session.id,
        role: "assistant",
        content: "Please provide more information.",
        renderType: "form",
        definition: formDefinition,
        data: missingFieldsData,
      };
    }
  } catch (error) {
    await log.debug(session.id, "Error in chat endpoint:", error + "");
    return {
      chatId: session.id,
      role: "assistant",
      content: "An error occurred while processing your request. " + error,
      renderType: "box",
      type: "error",
    };
  }
};
